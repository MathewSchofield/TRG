\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ricker_transiting_2014}
\citation{ricker_transiting_2014}
\citation{rauer_plato_2014}
\citation{debosscher_automated_2007}
\citation{sarro_automated_2009}
\citation{nun_supervised_2014}
\citation{elorrieta_machine_2016}
\citation{valenzuela_unsupervised_2018}
\citation{ness_cannon_2015}
\citation{hon_deep_2017}
\citation{hon_deep_2018}
\citation{bellinger_fundamental_2016}
\citation{davies_oscillation_2016}
\citation{lund_K2P2_2015}
\citation{baglin_corot:_2006}
\citation{thomas_galactic_2017}
\citation{pinsonneault_apokasc_2014}
\citation{hog_tycho-2_2000}
\citation{lindegren_gaia_2018}
\citation{gilliland_initial_2010}
\newlabel{firstpage}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}The dataset}{1}{section.2}}
\newlabel{sect: dataset}{{2}{1}{The dataset}{section.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The 1000 \ensuremath  {Kepler}\tmspace  +\medmuskip {.2222em}Red Giants from Davies et al. (in prep). The colourbar shows the relative density of points with Kernel Density Estimation. The evolutionary tracks range from 0.9-1.5\ensuremath  {M_{\odot }\tmspace  +\medmuskip {.2222em}}.}}{1}{figure.1}}
\newlabel{fig:dataset}{{1}{1}{The 1000 \kep Red Giants from Davies et al. (in prep). The colourbar shows the relative density of points with Kernel Density Estimation. The evolutionary tracks range from 0.9-1.5\msol }{figure.1}{}}
\citation{sullivan_transiting_2015}
\citation{hog_tycho-2_2000}
\citation{brown_kepler_2011}
\citation{kollmeier_sdss-v:_2017}
\citation{bilir_transformations_2008}
\citation{jordi_empirical_2006}
\citation{ricker_transiting_2014}
\citation{ballot_visibilities_2011}
\citation{campante_asteroseismic_2016}
\newlabel{eq:kep noise}{{1}{2}{The dataset}{equation.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Imputing Imag values}{2}{section.3}}
\newlabel{sect: impute}{{3}{2}{Imputing Imag values}{section.3}{}}
\newlabel{eq: i-I}{{5}{2}{Imputing Imag values}{equation.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The \ensuremath  {I_{\textrm  {mag}}\tmspace  +\medmuskip {.2222em}}distribution of the KIC stars used to test the random forest regression. The 'true' values used to test the algorithm are shown in blue. The black histogram shows the distribution of values that the random forest regression predicted for that dataset.}}{2}{figure.2}}
\newlabel{fig:imag test hist}{{2}{2}{The \imag distribution of the KIC stars used to test the random forest regression. The 'true' values used to test the algorithm are shown in blue. The black histogram shows the distribution of values that the random forest regression predicted for that dataset}{figure.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Modifying Kepler data to look like TESS}{2}{section.4}}
\newlabel{sect: tess-like}{{4}{2}{Modifying Kepler data to look like TESS}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The true \ensuremath  {I_{\textrm  {mag}}\tmspace  +\medmuskip {.2222em}}values of the KIC stars use to test the algorithm, compared to their predicted values. The mean difference between the two sets of values is -0.01 mag, with a standard deviation of just 0.27 mag.}}{3}{figure.3}}
\newlabel{fig:imag test scatter}{{3}{3}{The true \imag values of the KIC stars use to test the algorithm, compared to their predicted values. The mean difference between the two sets of values is -0.01 mag, with a standard deviation of just 0.27 mag}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The \ensuremath  {I_{\textrm  {mag}}\tmspace  +\medmuskip {.2222em}}distribution of the KIC stars used to train the random forest regression is shown in blue. The predicted values for the stars without $I$-band magnitudes is shown in black.}}{3}{figure.4}}
\newlabel{fig:imag train}{{4}{3}{The \imag distribution of the KIC stars used to train the random forest regression is shown in blue. The predicted values for the stars without $I$-band magnitudes is shown in black}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The Power spectra of KIC 9535399 is plotted three times with moving medians in black. The original Power Spectra is plotted in grey. The power spectra after making the data look like TESS are plotted in blue. The subplot on the bottom left shows 1 year of TESS observation (the maximum). The subplot on the bottom right column shows 27-days (the minimum).}}{3}{figure.5}}
\newlabel{Power Spectra}{{5}{3}{The Power spectra of KIC 9535399 is plotted three times with moving medians in black. The original Power Spectra is plotted in grey. The power spectra after making the data look like TESS are plotted in blue. The subplot on the bottom left shows 1 year of TESS observation (the maximum). The subplot on the bottom right column shows 27-days (the minimum)}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The Power Spectra of KIC 6768319. The original power spectra is in grey. The data were transformed into 1 year and 27 days of TESS observation. The moving median of these transformations are overplotted.}}{3}{figure.6}}
\newlabel{overplotted PS}{{6}{3}{The Power Spectra of KIC 6768319. The original power spectra is in grey. The data were transformed into 1 year and 27 days of TESS observation. The moving median of these transformations are overplotted}{figure.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Detection Test}{3}{section.5}}
\newlabel{sect: det_test}{{5}{3}{Detection Test}{section.5}{}}
\citation{mosser_characterization_2012}
\citation{chaplin_predicting_2011}
\citation{chaplin_predicting_2011}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The SNR spectrum of KIC 10587122 after background subtraction. The SNR values of the radial modes in the star were extracted from this spectrum. The highest SNR value within the linewidth of each mode is taken to be the SNR value of that mode. The mode linewidths are shown as blue lines. The values of every mode in the original Kepler spectrum are plotted as blue points. The overplotted orange points are the SNR values after degrading the signal to 1 year of TESS observation. Similarly, the green points are the SNR values of 27 days of TESS observations. The white noise level and reduced observation time severely reduce the SNR of TESS observations compared to \ensuremath  {Kepler}\tmspace  +\medmuskip {.2222em}.}}{4}{figure.7}}
\newlabel{snr}{{7}{4}{The SNR spectrum of KIC 10587122 after background subtraction. The SNR values of the radial modes in the star were extracted from this spectrum. The highest SNR value within the linewidth of each mode is taken to be the SNR value of that mode. The mode linewidths are shown as blue lines. The values of every mode in the original Kepler spectrum are plotted as blue points. The overplotted orange points are the SNR values after degrading the signal to 1 year of TESS observation. Similarly, the green points are the SNR values of 27 days of TESS observations. The white noise level and reduced observation time severely reduce the SNR of TESS observations compared to \kep }{figure.7}{}}
\newlabel{eq:snr}{{8}{4}{Detection Test}{equation.8}{}}
\newlabel{eq:pdet}{{9}{4}{Detection Test}{equation.9}{}}
\newlabel{eq:prob}{{10}{4}{Detection Test}{equation.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces A plot showing the result of the detection test, after running on every mode in 20 stars. The results of the original power spectra are plotted in blue. The results of 1 year of TESS observation are in orange. 27 days of TESS observation is in green. At this short an observation, detecting individual modes will be extremely difficult.}}{4}{figure.8}}
\newlabel{fig: modes}{{8}{4}{A plot showing the result of the detection test, after running on every mode in 20 stars. The results of the original power spectra are plotted in blue. The results of 1 year of TESS observation are in orange. 27 days of TESS observation is in green. At this short an observation, detecting individual modes will be extremely difficult}{figure.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Classification}{4}{section.6}}
\newlabel{sect: classifier}{{6}{4}{Classification}{section.6}{}}
\citation{pinsonneault_apokasc_2014}
\citation{lindegren_gaia_2018}
\citation{hog_tycho-2_2000}
\citation{wegner_technique_1960}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces An example of the X-dataset for 1 year of TESS-like observations. Every star has it's magnitude perturbed 100 times. See Table \ref  {tab: y dataset} for the equivalent Y-dataset.}}{5}{table.1}}
\newlabel{tab: x dataset}{{1}{5}{An example of the X-dataset for 1 year of TESS-like observations. Every star has it's magnitude perturbed 100 times. See Table \ref {tab: y dataset} for the equivalent Y-dataset}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Preparing the data}{5}{subsection.6.1}}
\newlabel{sect: prep}{{6.1}{5}{Preparing the data}{subsection.6.1}{}}
\newlabel{eq:class}{{11}{5}{Preparing the data}{equation.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Target selection using a classifier}{5}{subsection.6.2}}
\newlabel{sect: class-results}{{6.2}{5}{Target selection using a classifier}{subsection.6.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces An example of the Y-dataset for 1 year of TESS-like observations. Every star has it's magnitude perturbed 100 times. White noise is then added to the timeseries and mode detection probabilities are calculated for 3 radial modes centred around \ensuremath  {\nu _{\textrm  {max}}}. Lastly, these probabilities are put into discrete classes [0, 1 or 2]. The radial mode closest to \ensuremath  {\nu _{\textrm  {max}}}is \ensuremath  {P_{\rm  det}\tmspace  +\medmuskip {.2222em}}(2). See Table \ref  {tab: x dataset} for the equivalent X-dataset.}}{5}{table.2}}
\newlabel{tab: y dataset}{{2}{5}{An example of the Y-dataset for 1 year of TESS-like observations. Every star has it's magnitude perturbed 100 times. White noise is then added to the timeseries and mode detection probabilities are calculated for 3 radial modes centred around \numax . Lastly, these probabilities are put into discrete classes [0, 1 or 2]. The radial mode closest to \numax is \pdet (2). See Table \ref {tab: x dataset} for the equivalent X-dataset}{table.2}{}}
\newlabel{scikit}{{3}{5}{}{Hfootnote.4}{}}
\citation{kjeldsen_amplitudes_1995}
\citation{mathur_granulation_2011}
\citation{chaplin_predicting_2011}
\citation{elsworth_new_2017}
\citation{chaplin_asteroseismology_2013}
\citation{bedding_solar-like_2011}
\citation{beck_kepler_2011}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Results of the classifier on the original \ensuremath  {Kepler}\tmspace  +\medmuskip {.2222em}dataset, and the 1-year and 27-day TESS datasets. The 'Precision' column gives the average weighted precision of the classifier across the 3 classes [0, 1, 2] and 3 features [\ensuremath  {P_{\rm  det}\tmspace  +\medmuskip {.2222em}}(1), \ensuremath  {P_{\rm  det}\tmspace  +\medmuskip {.2222em}}(2), \ensuremath  {P_{\rm  det}\tmspace  +\medmuskip {.2222em}}(3)].}}{6}{table.3}}
\newlabel{tab: results}{{3}{6}{Results of the classifier on the original \kep dataset, and the 1-year and 27-day TESS datasets. The 'Precision' column gives the average weighted precision of the classifier across the 3 classes [0, 1, 2] and 3 features [\pdet (1), \pdet (2), \pdet (3)]}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Feature Importance}{6}{subsection.6.3}}
\newlabel{sect: feature importance}{{6.3}{6}{Feature Importance}{subsection.6.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The feature importance of the 5 X-data columns.}}{6}{figure.9}}
\newlabel{fig:feature}{{9}{6}{The feature importance of the 5 X-data columns}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Comparing results between different evolutionary states}{6}{subsection.6.4}}
\newlabel{sect: evo states}{{6.4}{6}{Comparing results between different evolutionary states}{subsection.6.4}{}}
\citation{pinsonneault_apokasc_2014}
\citation{gaia_collaboration_gaia_2016}
\citation{hog_tycho-2_2000}
\citation{ricker_transiting_2014}
\bibstyle{mnras}
\bibdata{TRG}
\bibcite{baglin_corot:_2006}{{1}{2006}{{Baglin et~al.}}{{Baglin et~al.,}}}
\bibcite{ballot_visibilities_2011}{{2}{2011}{{Ballot et~al.}}{{Ballot, Barban \& van't Veer-Menneret}}}
\bibcite{beck_kepler_2011}{{3}{2011}{{Beck et~al.}}{{Beck et~al.,}}}
\bibcite{bedding_solar-like_2011}{{4}{2011}{{Bedding}}{{Bedding}}}
\bibcite{bellinger_fundamental_2016}{{5}{2016}{{Bellinger et~al.}}{{Bellinger, Angelou, Hekker, Basu, Ball \& Guggenberger}}}
\bibcite{bilir_transformations_2008}{{6}{2008}{{Bilir et~al.}}{{Bilir, Ak, Karaali, Cabrera-Lavers, Chonis \& Gaskell}}}
\bibcite{brown_kepler_2011}{{7}{2011}{{Brown et~al.}}{{Brown, Latham, Everett \& Esquerdo}}}
\bibcite{campante_asteroseismic_2016}{{8}{2016}{{Campante et~al.}}{{Campante et~al.,}}}
\bibcite{chaplin_asteroseismology_2013}{{9}{2013}{{Chaplin \& Miglio}}{{Chaplin \& Miglio}}}
\bibcite{chaplin_predicting_2011}{{10}{2011}{{Chaplin et~al.}}{{Chaplin et~al.,}}}
\bibcite{davies_oscillation_2016}{{11}{2016}{{Davies et~al.}}{{Davies et~al.,}}}
\bibcite{debosscher_automated_2007}{{12}{2007}{{Debosscher et~al.}}{{Debosscher, Sarro, Aerts, Cuypers, Vandenbussche, Garrido \& Solano}}}
\bibcite{elorrieta_machine_2016}{{13}{2016}{{Elorrieta et~al.}}{{Elorrieta et~al.,}}}
\bibcite{elsworth_new_2017}{{14}{2017}{{Elsworth et~al.}}{{Elsworth, Hekker, Basu \& R.~Davies}}}
\bibcite{gaia_collaboration_gaia_2016}{{15}{2016}{{{Gaia Collaboration} et~al.}}{{{Gaia Collaboration} et~al.,}}}
\bibcite{gilliland_initial_2010}{{16}{2010}{{Gilliland et~al.}}{{Gilliland et~al.,}}}
\bibcite{hog_tycho-2_2000}{{17}{2000}{{Hog et~al.}}{{Hog et~al.,}}}
\bibcite{hon_deep_2017}{{18}{2017}{{Hon et~al.}}{{Hon, Stello \& Yu}}}
\bibcite{hon_deep_2018}{{19}{2018}{{Hon et~al.}}{{Hon, Stello \& Yu}}}
\bibcite{jordi_empirical_2006}{{20}{2006}{{Jordi et~al.}}{{Jordi, Grebel \& Ammon}}}
\bibcite{kjeldsen_amplitudes_1995}{{21}{1995}{{Kjeldsen \& Bedding}}{{Kjeldsen \& Bedding}}}
\bibcite{kollmeier_sdss-v:_2017}{{22}{2017}{{Kollmeier et~al.}}{{Kollmeier et~al.,}}}
\bibcite{lindegren_gaia_2018}{{23}{2018}{{Lindegren et~al.}}{{Lindegren et~al.,}}}
\bibcite{lund_K2P2_2015}{{24}{2015}{{Lund et~al.}}{{Lund, Handberg, Davies, Chaplin \& Jones}}}
\bibcite{mathur_granulation_2011}{{25}{2011}{{Mathur et~al.}}{{Mathur et~al.,}}}
\bibcite{mosser_characterization_2012}{{26}{2012}{{Mosser et~al.}}{{Mosser et~al.,}}}
\bibcite{ness_cannon_2015}{{27}{2015}{{Ness et~al.}}{{Ness, Hogg, Rix, Ho \& Zasowski}}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Results of the classifier when RGB, RC and 2CL stars are separated. Results are shown when the data are treated like \ensuremath  {Kepler}\tmspace  +\medmuskip {.2222em}stars, and when they are degraded to look like 1-year and 27-day TESS observation. The 'Precision' column gives the average weighted precision of the classifier across the 3 classes [0, 1, 2] and 3 features [\ensuremath  {P_{\rm  det}\tmspace  +\medmuskip {.2222em}}(1), \ensuremath  {P_{\rm  det}\tmspace  +\medmuskip {.2222em}}(2), \ensuremath  {P_{\rm  det}\tmspace  +\medmuskip {.2222em}}(3)].}}{7}{table.4}}
\newlabel{tab: evo results}{{4}{7}{Results of the classifier when RGB, RC and 2CL stars are separated. Results are shown when the data are treated like \kep stars, and when they are degraded to look like 1-year and 27-day TESS observation. The 'Precision' column gives the average weighted precision of the classifier across the 3 classes [0, 1, 2] and 3 features [\pdet (1), \pdet (2), \pdet (3)]}{table.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{7}{section.7}}
\newlabel{sect: conc}{{7}{7}{Conclusion}{section.7}{}}
\bibcite{nun_supervised_2014}{{28}{2014}{{Nun et~al.}}{{Nun, Pichara, Protopapas \& Kim}}}
\bibcite{pinsonneault_apokasc_2014}{{29}{2014}{{Pinsonneault et~al.}}{{Pinsonneault et~al.,}}}
\bibcite{rauer_plato_2014}{{30}{2014}{{Rauer et~al.}}{{Rauer et~al.,}}}
\bibcite{ricker_transiting_2014}{{31}{2014}{{Ricker et~al.}}{{Ricker et~al.,}}}
\bibcite{sarro_automated_2009}{{32}{2009}{{Sarro et~al.}}{{Sarro, Debosscher, LÃ³pez \& Aerts}}}
\bibcite{sullivan_transiting_2015}{{33}{2015}{{Sullivan et~al.}}{{Sullivan et~al.,}}}
\bibcite{thomas_galactic_2017}{{34}{2017}{{Thomas et~al.}}{{Thomas, Stevenson, Gittins, Miglio, Davies, Girardi, Campante \& Schofield}}}
\bibcite{valenzuela_unsupervised_2018}{{35}{2018}{{Valenzuela \& Pichara}}{{Valenzuela \& Pichara}}}
\bibcite{wegner_technique_1960}{{36}{1960}{{Wegner}}{{Wegner}}}
\newlabel{lastpage}{{7}{8}{Conclusion}{section.7}{}}
